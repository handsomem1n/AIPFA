# í†µí•© ìš´ë™ í”¼ë“œë°± ì‹œìŠ¤í…œ

BiLSTM ê¸°ë°˜ ìš´ë™ ë¶„ë¥˜ + Mediapipe ìì„¸ ë¶„ì„ + LLM í”¼ë“œë°± í†µí•© ì‹œìŠ¤í…œ

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
exercise_feedback_system/
â”œâ”€â”€ exercise_feedback_system.py   # ë©”ì¸ í†µí•© ì‹œìŠ¤í…œ
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ bilstm_classifier.py      # BiLSTM ìš´ë™ ë¶„ë¥˜ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ model.pt                  # í•™ìŠµëœ ëª¨ë¸ (ì¶”ê°€ í•„ìš”)
â”‚   â””â”€â”€ label_encoder.pkl         # Label encoder (ì¶”ê°€ í•„ìš”)
â”œâ”€â”€ feedback/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pose_analyzer.py          # Mediapipe ìì„¸ ë¶„ì„
â”‚   â””â”€â”€ llm_feedback.py           # LLM í”¼ë“œë°± ìƒì„±
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ gt_videos/                # Ground truth ì˜ìƒ
â”‚   â”‚   â”œâ”€â”€ lunge_gt.mp4
â”‚   â”‚   â””â”€â”€ highknees_gt.mp4
â”‚   â””â”€â”€ user_videos/              # ì‚¬ìš©ì ì˜ìƒ
â”œâ”€â”€ output/                       # ê²°ê³¼ ì¶œë ¥ ë””ë ‰í† ë¦¬
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸš€ ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

## ğŸ“ ì‚¬ìš©ë²•

### 1. ê¸°ë³¸ ì‚¬ìš©

```python
from exercise_feedback_system import ExerciseFeedbackSystem
import os

# ì‹œìŠ¤í…œ ì´ˆê¸°í™”
system = ExerciseFeedbackSystem(
    model_path="./models/model.pt",
    label_encoder_path="./models/label_encoder.pkl",
    openai_api_key=os.getenv("OPENAI_API_KEY")
)

# ë¹„ë””ì˜¤ ì²˜ë¦¬
result = system.process_video(
    user_video_path="./data/user_videos/user_lunge.mp4",
    output_dir="./output"
)

# ê²°ê³¼ í™•ì¸
print(f"ìš´ë™ ì¢…ë¥˜: {result['exercise_type']}")
print(f"ì‹ ë¢°ë„: {result['confidence']:.2%}")
print(f"\n{result['feedback_text']}")
```

### 2. GT ì˜ìƒ ì§€ì •

```python
result = system.process_video(
    user_video_path="./data/user_videos/user_lunge.mp4",
    gt_video_path="./data/gt_videos/lunge_gt.mp4",  # ì§ì ‘ ì§€ì •
    output_dir="./output"
)
```

## ğŸ”§ ì£¼ìš” ê¸°ëŠ¥

### 1. BiLSTM ìš´ë™ ë¶„ë¥˜
- ê´€ì ˆ ì‹œí€€ìŠ¤ ë°ì´í„°ë¡œ ìš´ë™ ì¢…ë¥˜ ìë™ ë¶„ë¥˜
- ëŸ°ì§€, í•˜ì´ë‹ˆì¦ˆ ë“± ë‹¤ì–‘í•œ ìš´ë™ ì§€ì›

### 2. ìì„¸ ë¶„ì„
- Mediapipe ê¸°ë°˜ ì‹¤ì‹œê°„ ê´€ì ˆ ì¶”ì¶œ
- GT vs ì‚¬ìš©ì ì˜ìƒ ë¹„êµ
- OKS ì ìˆ˜, ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
- í”„ë ˆì„ë³„ Good/Fast/Slow/NG ë¶„ë¥˜

### 3. ì‹œê°í™”
- ë¶€ìœ„ë³„ ìƒ‰ìƒìœ¼ë¡œ ìì„¸ ì •í™•ë„ í‘œì‹œ
- GTì™€ ì‚¬ìš©ì ì˜ìƒ ì¢Œìš° ë¹„êµ
- í”¼ë“œë°± ì˜ìƒ ìë™ ìƒì„±

### 4. LLM í”¼ë“œë°±
- ìš´ë™ë³„ ë§ì¶¤ í”„ë¡¬í”„íŠ¸
- ìì—°ìŠ¤ëŸ¬ìš´ ì½”ì¹˜ ìŠ¤íƒ€ì¼ í”¼ë“œë°±
- ê°œì„  ë°©í–¥ êµ¬ì²´ì  ì œì‹œ

## ğŸ“Š ì¶œë ¥ ê²°ê³¼

- **feedback_video.mp4**: ì‹œê°í™”ëœ í”¼ë“œë°± ì˜ìƒ
- **feedback_full.json**: í”„ë ˆì„ë³„ ìƒì„¸ ë¶„ì„ ë°ì´í„°
- **feedback_summary.json**: ì „ì²´ ìš”ì•½ í†µê³„
- **feedback_text**: LLM ìƒì„± í…ìŠ¤íŠ¸ í”¼ë“œë°±

## ğŸ§ª ëª¨ë¸ í•™ìŠµ (ì„ íƒ)

bilstm2.pyë¥¼ ì°¸ê³ í•˜ì—¬ ìƒˆë¡œìš´ ë°ì´í„°ë¡œ ëª¨ë¸ ì¬í•™ìŠµ ê°€ëŠ¥:

```python
# Train/Test ë¶„ë¦¬
train_df, test_df = extract_test_train(df)

# ëª¨ë¸ í•™ìŠµ
model = PoseBiLSTMClassifier(INPUT_SIZE, HIDDEN_SIZE, num_classes)
# ... í•™ìŠµ ë£¨í”„

# ì €ì¥
torch.save(model.state_dict(), "./models/model.pt")
joblib.dump(le, "./models/label_encoder.pkl")
```

## ğŸ¯ ì»¤ìŠ¤í„°ë§ˆì´ì§•

### ìƒˆë¡œìš´ ìš´ë™ ì¶”ê°€

1. **GT ì˜ìƒ ì¶”ê°€**: `data/gt_videos/`ì— ì˜ìƒ ì¶”ê°€
2. **í”„ë¡¬í”„íŠ¸ ì‘ì„±**: `feedback/llm_feedback.py`ì— í”„ë¡¬í”„íŠ¸ í•¨ìˆ˜ ì¶”ê°€
3. **ë§¤í•‘ ë“±ë¡**: `exercise_feedback_system.py`ì˜ `_get_default_gt()` ìˆ˜ì •

```python
def _get_default_gt(self, exercise_type: str) -> str:
    gt_mapping = {
        "lunge": "./data/gt_videos/lunge_gt.mp4",
        "highknees": "./data/gt_videos/highknees_gt.mp4",
        "new_exercise": "./data/gt_videos/new_exercise_gt.mp4",  # ì¶”ê°€
    }
    return gt_mapping.get(exercise_type, "./data/gt_videos/default_gt.mp4")
```

## ğŸ” íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±
```python
# CPU ëª¨ë“œë¡œ ì‹¤í–‰
torch.device('cpu')
```

### OpenCV ì¸ì½”ë” ì—ëŸ¬
```python
# ì½”ë± ë³€ê²½
cv2.VideoWriter_fourcc(*"avc1")  # ë˜ëŠ” "XVID"
```

## ğŸ“„ ë¼ì´ì„¼ìŠ¤

MIT License

## ğŸ‘¥ ê¸°ì—¬ì

- BiLSTM ëª¨ë¸: bilstm2.py
- ìì„¸ ë¶„ì„: pose_feedback.py
- í†µí•©: íŒ€ ê³µë™ ì‘ì—…
