# -*- coding: utf-8 -*-
"""pose_feedback.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a9yq3B7DETIbXl-WgyOTlgsO4Ml0zPPf
"""

!pip install mediapipe opencv-python-headless numpy

"""# 원본 영상 관절 빨간색"""

import cv2, math, numpy as np
import mediapipe as mp
import matplotlib.cm as cm
import json

POSE_LANDMARKS = mp.solutions.pose.PoseLandmark

# 주요 관절쌍 (팔, 다리, 몸통)
VEC_PAIRS = [
    (POSE_LANDMARKS.LEFT_SHOULDER, POSE_LANDMARKS.LEFT_ELBOW),
    (POSE_LANDMARKS.LEFT_ELBOW, POSE_LANDMARKS.LEFT_WRIST),
    (POSE_LANDMARKS.RIGHT_SHOULDER, POSE_LANDMARKS.RIGHT_ELBOW),
    (POSE_LANDMARKS.RIGHT_ELBOW, POSE_LANDMARKS.RIGHT_WRIST),
    (POSE_LANDMARKS.LEFT_HIP, POSE_LANDMARKS.LEFT_KNEE),
    (POSE_LANDMARKS.LEFT_KNEE, POSE_LANDMARKS.LEFT_ANKLE),
    (POSE_LANDMARKS.RIGHT_HIP, POSE_LANDMARKS.RIGHT_KNEE),
    (POSE_LANDMARKS.RIGHT_KNEE, POSE_LANDMARKS.RIGHT_ANKLE),
    (POSE_LANDMARKS.LEFT_SHOULDER, POSE_LANDMARKS.RIGHT_SHOULDER),
    (POSE_LANDMARKS.LEFT_HIP, POSE_LANDMARKS.RIGHT_HIP),
]

# 시각화할 스켈레톤 선분
EDGES = [
    (int(POSE_LANDMARKS.LEFT_SHOULDER), int(POSE_LANDMARKS.RIGHT_SHOULDER)),
    (int(POSE_LANDMARKS.LEFT_SHOULDER), int(POSE_LANDMARKS.LEFT_ELBOW)),
    (int(POSE_LANDMARKS.LEFT_ELBOW), int(POSE_LANDMARKS.LEFT_WRIST)),
    (int(POSE_LANDMARKS.RIGHT_SHOULDER), int(POSE_LANDMARKS.RIGHT_ELBOW)),
    (int(POSE_LANDMARKS.RIGHT_ELBOW), int(POSE_LANDMARKS.RIGHT_WRIST)),
    (int(POSE_LANDMARKS.LEFT_HIP), int(POSE_LANDMARKS.RIGHT_HIP)),
    (int(POSE_LANDMARKS.LEFT_HIP), int(POSE_LANDMARKS.LEFT_KNEE)),
    (int(POSE_LANDMARKS.LEFT_KNEE), int(POSE_LANDMARKS.LEFT_ANKLE)),
    (int(POSE_LANDMARKS.RIGHT_HIP), int(POSE_LANDMARKS.RIGHT_KNEE)),
    (int(POSE_LANDMARKS.RIGHT_KNEE), int(POSE_LANDMARKS.RIGHT_ANKLE)),
]

# 관절 추출
def extract_landmarks(video_path, max_frames=99999, stride=1):
    mp_pose = mp.solutions.pose
    cap = cv2.VideoCapture(video_path)
    frames=[]
    with mp_pose.Pose(static_image_mode=False, model_complexity=1) as pose:
        idx=0
        while True:
            ret, frame = cap.read()
            if not ret or idx>=max_frames: break
            if idx%stride!=0:
                idx+=1; continue
            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            res = pose.process(rgb)
            if res.pose_landmarks:
                h,w = frame.shape[:2]
                pts=[]
                for lm in res.pose_landmarks.landmark:
                    pts.append((lm.x*w, lm.y*h, lm.visibility))
                frames.append({"pts":np.array(pts, dtype=np.float32), "frame":frame})
            idx+=1
    cap.release()
    return frames

def _unit_vec(v):
    n=np.linalg.norm(v)+1e-8
    return v/n

# 단위 벡터 계산 (포즈 방향 특징으로 사용하기 위해)
def vectorize(pts):
    vecs=[]
    for a,b in VEC_PAIRS:
        pa=np.array(pts[int(a)][:2]); pb=np.array(pts[int(b)][:2])
        vecs.append(_unit_vec(pb-pa))
    return np.concatenate(vecs, axis=0)

# 바운딩 박스 대각선 길이로 스케일(사람크기, 카메라 거리 보정용)
def bbox_scale(pts):
    xs, ys = pts[:,0], pts[:,1]
    w = (xs.max()-xs.min()); h=(ys.max()-ys.min())
    return math.sqrt(w*w+h*h)+1e-6

def oks_score(ptsA, ptsB, k=0.5):
    s = bbox_scale(ptsA)
    d2 = np.sum((ptsA[:,:2]-ptsB[:,:2])**2, axis=1)
    oks = np.exp(-d2 / (2*(s**2)*(k**2)))
    return float(np.mean(oks))

# 코사인 유사도를 [0, 1]범위로 스케일
def cosine01(a, b):
    c = float(np.dot(a,b) / ((np.linalg.norm(a)+1e-8)*(np.linalg.norm(b)+1e-8)))
    return 0.5*(c+1.0)

# 스케일 정규화된 L2 거리
def l2_distance(a_pts, b_pts):
    scale = bbox_scale(a_pts)
    return float(np.linalg.norm((a_pts[:,:2]-b_pts[:,:2]).reshape(-1)) / scale)

#GT의 프레임 주변에서 코사인 유사도가 최대인 프레임 탐색
def best_match_idx(gt_vecs, usr_vecs, center, win=5):
    lo=max(0, center-win); hi=min(len(usr_vecs)-1, center+win)
    best_i, best_s = center, -1.0
    for j in range(lo, hi+1):
        s = cosine01(gt_vecs[center], usr_vecs[j])
        if s>best_s: best_s, best_i = s, j
    return best_i, best_s

# (NG, Fast, Slow, Good 결정)
def classify_frame(gt_i, best_j, l2_val, l2_th=0.5, speed_tol=2):
    if l2_val > l2_th:
        return "NG"
    delta = best_j - gt_i
    if delta >  speed_tol: return "Fast"
    if delta < -speed_tol: return "Slow"
    return "Good"

# --- Colormap 기반 색상 ---
_cmap = cm.get_cmap('turbo')  # turbo/viridis 권장

def compute_score_range(all_scores, low_p=5, high_p=95):
    """세션 전체 점수 분포에서 smin, smax 계산"""
    smin = np.percentile(all_scores, low_p)
    smax = np.percentile(all_scores, high_p)
    if smax <= smin:  # 안전장치
        smin, smax = 0.0, 1.0
    return smin, smax

def score_to_color(score: float, smin: float, smax: float):
    """점수를 세션 분포 기반으로 정규화 → colormap 색상"""
    x = (score - smin) / (smax - smin + 1e-8)
    x = float(np.clip(x, 0.0, 1.0))
    rgba = _cmap(x)
    r,g,b,a = [int(val*255) for val in rgba]
    return (b,g,r)  # OpenCV BGR

# 부위별 코사인 유사도
def pairwise_cosine(pa1, pb1, pa2, pb2):
    v1 = _unit_vec(pa1 - pb1)
    v2 = _unit_vec(pa2 - pb2)
    c = np.dot(v1,v2) / (np.linalg.norm(v1)*np.linalg.norm(v2)+1e-8)
    return 0.5*(c+1.0)

# 부위별 색상 스켈레톤 (점수 분포 정규화 적용)
def draw_skeleton_per_edge(img, pts_gt, pts_usr, smin=0.0, smax=1.0, edges=EDGES):
    for a,b in edges:
        pa_gt, pb_gt = pts_gt[a][:2], pts_gt[b][:2]
        pa_usr, pb_usr = pts_usr[a][:2], pts_usr[b][:2]

        score = pairwise_cosine(np.array(pa_gt), np.array(pb_gt),
                                np.array(pa_usr), np.array(pb_usr))
        color = score_to_color(score, smin, smax)

        cv2.line(img, (int(pts_usr[a][0]), int(pts_usr[a][1])),
                      (int(pts_usr[b][0]), int(pts_usr[b][1])), color, 3)
        cv2.circle(img, (int(pts_usr[a][0]), int(pts_usr[a][1])), 4, color, -1)
        cv2.circle(img, (int(pts_usr[b][0]), int(pts_usr[b][1])), 4, color, -1)

def evaluate(gt_video, usr_video, win=5, speed_tol=2, l2_th=0.5,
             save_path="out_feedback.mp4",
             full_json_path="out_feedback_full.json",
             summary_json_path="out_feedback_summary.json"):
    gt_frames = extract_landmarks(gt_video)
    usr_frames = extract_landmarks(usr_video)
    gt_vecs   = [vectorize(f["pts"]) for f in gt_frames]
    usr_vecs  = [vectorize(f["pts"]) for f in usr_frames]

    # --- 1차 패스: 전체 점수 분포 수집 ---
    all_scores = []
    N = min(len(gt_frames), len(usr_frames))
    for i in range(N):
        j, cos_s = best_match_idx(gt_vecs, usr_vecs, i, win=win)
        oks = oks_score(gt_frames[i]["pts"], usr_frames[j]["pts"])
        final_score = cos_s * oks
        all_scores.append(final_score)
    smin, smax = compute_score_range(all_scores)

    # --- 2차 패스: 시각화 + 통계 + JSON 데이터 수집 ---
    H,W = gt_frames[0]["frame"].shape[:2]
    fps = int(cv2.VideoCapture(gt_video).get(cv2.CAP_PROP_FPS)) or 20
    out = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*"mp4v"), fps, (W*2, H))

    stats = {"Good":0,"Fast":0,"Slow":0,"NG":0}
    frame_results = []
    joint_accumulator = {}  # 관절별 점수 누적용

    for i in range(N):
        j, cos_s = best_match_idx(gt_vecs, usr_vecs, i, win=win)
        oks = oks_score(gt_frames[i]["pts"], usr_frames[j]["pts"])
        final_score = cos_s * oks
        l2v = l2_distance(gt_frames[i]["pts"], usr_frames[j]["pts"])
        label = classify_frame(i, j, l2v, l2_th=l2_th, speed_tol=speed_tol)
        stats[label]+=1

        # --- 부위별 점수 저장 ---
        joint_scores = {}
        for a,b in EDGES:
            pa_gt, pb_gt = gt_frames[i]["pts"][a][:2], gt_frames[i]["pts"][b][:2]
            pa_usr, pb_usr = usr_frames[j]["pts"][a][:2], usr_frames[j]["pts"][b][:2]
            score = pairwise_cosine(np.array(pa_gt), np.array(pb_gt),
                                    np.array(pa_usr), np.array(pb_usr))
            joint_scores[f"{a}-{b}"] = round(float(score),3)

            # 평균 계산 위해 누적
            joint_accumulator.setdefault(f"{a}-{b}", []).append(score)

        frame_results.append({
            "frame_idx": i,
            "match_idx": j,
            "label": label,
            "final_score": round(float(final_score),3),
            "joint_scores": joint_scores
        })

        # --- 영상 시각화 ---
        left = gt_frames[i]["frame"].copy()
        right = usr_frames[j]["frame"].copy()

        draw_skeleton_per_edge(left, gt_frames[i]["pts"], gt_frames[i]["pts"], smin, smax)
        draw_skeleton_per_edge(right, gt_frames[i]["pts"], usr_frames[j]["pts"], smin, smax)

        cv2.putText(left,  f"GT idx={i}", (10,30),  cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 2)
        cv2.putText(right, f"USR idx={j}", (10,30),  cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 2)
        cv2.putText(right, f"{label} score={final_score:.2f}", (10,70),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,0), 2)

        #  프레임 크기 맞추기 (GT 크기에 맞게 USER 리사이즈)
        right_resized = cv2.resize(right, (W, H))
        out.write(np.hstack([left, right_resized]))

    out.release()
    total = sum(stats.values())+1e-9
    summary = {k: round(v/total*100,1) for k,v in stats.items()}

    # --- 관절쌍별 평균 점수 ---
    avg_joint_scores = {k: round(float(np.mean(v)),3) for k,v in joint_accumulator.items()}

    # --- JSON 저장 ---
    # Full 버전 (프레임별 모든 결과)
    full_data = {
        "summary": summary,
        "frames": frame_results
    }
    with open(full_json_path, "w") as f:
        json.dump(full_data, f, indent=2)

    # Summary 버전 (요약 + 평균 joint_scores)
    summary_data = {
        "summary": summary,
        "average_joint_scores": avg_joint_scores
    }
    with open(summary_json_path, "w") as f:
        json.dump(summary_data, f, indent=2)

    return summary

# 3. 실행
stats = evaluate("/content/GT.mp4", "/content/TEST.mp4", save_path="out_feedback.mp4")
print("Feedback Ratio:", stats)

# 4. 결과 다운로드
from google.colab import files
files.download("out_feedback.mp4")

"""## 스쿼트 영상에 대한 프롬프트"""

import os
os.environ["OPENAI_API_KEY"] = "키 넣어주세요"

from openai import OpenAI
import json

client = OpenAI()

# 3. summary JSON 불러오기
with open("out_feedback_summary.json", "r") as f:
    summary_data = json.load(f)

print("Summary JSON:", summary_data)

# 4. 프롬프트 생성 함수
def build_squat_prompt(summary_json, exercise="스쿼트"):
    summary = summary_json["summary"]
    avg_scores = summary_json["average_joint_scores"]

    # 절대 기준 컷라인 설명 포함
    prompt = f"""
너는 운동 코치 AI야. 아래는 사용자의 {exercise} 동작 평가 결과야.
JSON 데이터를 보고, 사용자가 이해할 수 있게 피드백을 해줘.

** 스쿼트에 대한 설명
  스쿼트는 대표적인 하체 근력 운동으로, 허벅지와 엉덩이 근육을 강화하는 데 효과적이야
  올바른 스쿼트 자세는 다음과 같습니다:
  1. 허리를 곧게 세우고 가슴을 편 상태에서 시작한다.
  2. 무릎이 발끝을 넘지 않도록 한다.
  3. 무릎이 안쪽으로 모이지 않고 바깥으로 안정적으로 유지해야 한다.
  4. 엉덩이를 뒤로 빼며 앉아 허벅지가 지면과 평행할 때까지 내려간다.
  5. 팔은 균형을 위해 앞으로 뻗는다.

** 주요 관절에 대한 설명
	•	11: 왼쪽 어깨
	•	12: 오른쪽 어깨
	•	13: 왼쪽 팔꿈치
	•	14: 오른쪽 팔꿈치
	•	15: 왼쪽 손목
	•	16: 오른쪽 손목
	•	23: 왼쪽 엉덩이
	•	24: 오른쪽 엉덩이
	•	25: 왼쪽 무릎
	•	26: 오른쪽 무릎
	•	27: 왼쪽 발목
	•	28: 오른쪽 발목 (

** 평가 기준 (엄격 모드):
- joint_score >= 0.999 : 매우 잘함
- 0.985 ~ 0.997 : 부족
- 0.975 ~ 0.985 : 매우부족
- < 0.975 : 잘못됨

# 결과 요약:
라벨 비율 = {summary}
평균 관절 점수 = {avg_scores}

# 출력 지침(스쿼트):
1. 스쿼트의 핵심 동작 기준과 비교해서 설명한다.
2. 주요 관절의 결과들을 보고 정확하게 피드백을 해준다. 하지만 관절 점수는 출력할 필요가 없다. 설명만 반드시 출력한다.
3. 전체적인 동작 평가 (라벨 비율 기반).
4. 상체(어깨/팔), 하체(엉덩이/무릎/발목) 강점과 부족한 점.
5. 개선할 수 있는 구체적인 조언을 제시.




"""
    return prompt

# 5. LLM 호출
prompt = build_prompt(summary_data, exercise="스쿼트")

response = client.chat.completions.create(
    model="gpt-4o-mini",   # Colab에서는 작은 모델 추천, 필요하면 gpt-4o로 교체
    messages=[{"role":"user","content": prompt}],
    temperature=0.7
)

print("\n LLM 피드백 결과:\n")
print(response.choices[0].message.content)

"""# 런지 정면 영상에 대한 프롬프트"""

# 4. 프롬프트 생성 함수
# 정면용 프롬프트
def lunge_front_prompt(summary_json, exercise="런지"):
    summary = summary_json["summary"]
    avg_scores = summary_json["average_joint_scores"]

    prompt = f"""
너는 운동 코치 AI야. 아래는 사용자의 런지 정면 동작 평가 결과야.
JSON 데이터를 보고, 사용자가 이해할 수 있게 피드백을 해줘.

** 런지에 대한 설명
  런지는 분할 스탠스에서 전·후발을 두고 실시하는 하지 복합운동으로, 고관절·슬관절·거족관절의 동시적 굴곡/신전 협응을 통해
  대둔근·슬괵근·대퇴사두근·비복근/가자미근 등의 근력을 증진한다. 체간의 중립 유지와 하지 정렬 제어가 핵심이다.

** 주요 관절에 대한 설명
\t• 11: 왼쪽 어깨
\t• 12: 오른쪽 어깨
\t• 13: 왼쪽 팔꿈치
\t• 14: 오른쪽 팔꿈치
\t• 15: 왼쪽 손목
\t• 16: 오른쪽 손목
\t• 23: 왼쪽 엉덩이
\t• 24: 오른쪽 엉덩이
\t• 25: 왼쪽 무릎
\t• 26: 오른쪽 무릎
\t• 27: 왼쪽 발목
\t• 28: 오른쪽 발목

** 정면에서 바라봤을 때 런지 자세에 대한 설명
  정면 기준의 올바른 런지 핵심은 다음과 같다:
  1) 무릎 정렬: 전·후발의 무릎(25, 26)은 각각 두 번째 발가락 방향과 일직선을 유지하며 내반/외반(안쪽/바깥쪽 붕괴)을 보이지 않는다.
  2) 골반 수평: 좌·우 고관절(23, 24) 연결선이 수평에 가깝고, 하강 시 한쪽이 과도하게 떨어지지 않는다(Trendelenburg 방지).
  3) 체간 대칭: 어깨선(11, 12)이 수평에 가깝고 과도한 측굴/회전을 보이지 않는다.
  4) 발 접지: 전발은 모지구·소지구·뒤꿈치의 3점 접지를 유지하고, 과도한 회내/회외가 나타나지 않는다.
  5) 보폭/보폭폭: 보폭폭은 너무 좁지 않아 측면 흔들림을 최소화하며, 좌우 대칭을 유지한다.


** 평가 기준 (엄격 모드):
- joint_score >= 0.999 : 매우 잘함
- 0.985 ~ 0.997 : 부족
- 0.975 ~ 0.985 : 매우부족
- < 0.975 : 잘못됨

# 결과 요약:
라벨 비율 = {summary}
평균 관절 점수 = {avg_scores}

# 출력 지침:
1. 런지의 핵심 동작 기준과 비교해서 설명한다.
2. 주요 관절의 결과들을 보고 정확하게 피드백을 해준다. 하지만 관절 점수는 출력할 필요가 없다. 설명만 반드시 출력한다.
3. 전체적인 동작 평가 (라벨 비율 기반).
4. 상체(어깨/팔), 하체(엉덩이/무릎/발목) 강점과 부족한 점.
5. 개선할 수 있는 구체적인 조언을 제시.
"""
    return prompt

# 정면, 영상 1번에 대한 피드백
prompt = lunge_front_prompt(summary_data, exercise="런지")

response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role":"user","content": prompt}],
    temperature=0.7
)

print("\n LLM 피드백 결과:\n")
print(response.choices[0].message.content)

"""# LLM 답변 결과 :

안녕하세요! 런지 동작 평가 결과를 바탕으로 피드백을 드리겠습니다.

### 1. 런지의 핵심 동작 기준과 비교
런지 동작의 핵심은 무릎 정렬, 골반 수평, 체간 대칭, 발 접지, 보폭/보폭폭입니다. 전체적으로 보았을 때, 많은 부분에서 기준을 충족하지 못했습니다. 특히, 전·후발의 무릎 정렬과 발목의 접지 상태에서 문제가 발견되었습니다.

### 2. 주요 관절의 결과 분석
- **어깨**: 왼쪽 어깨와 오른쪽 어깨 모두 수평에 가까운 상태였으나, 일부 측면에서 약간의 부족함이 보였습니다.
- **팔꿈치**: 왼쪽과 오른쪽 팔꿈치 모두 기준보다 약간 부족한 정렬을 보였습니다.
- **엉덩이**: 엉덩이 관절은 매우 잘 정렬되어 있었으며, 이는 긍정적인 요소입니다.
- **무릎**: 오른쪽 무릎은 비교적 잘 정렬되었지만, 왼쪽 무릎은 기준에 미치지 못해 내반/외반 문제가 있었습니다.
- **발목**: 왼쪽 발목이 많이 부족하여 접지 상태가 불안정했습니다. 이는 전체적인 자세의 안정성을 저해합니다.

### 3. 전체적인 동작 평가
라벨 비율에서 'NG'가 57.1%로 매우 높은 비율을 차지하고 있습니다. 이는 전체 동작에서 많은 개선이 필요하다는 신호입니다. 'Good' 비율이 10.1%로 낮은 편이며, 동작의 정확성을 높이기 위한 노력이 필요합니다.

### 4. 상체와 하체 강점 및 부족한 점
- **상체 강점**: 어깨의 정렬이 양호하여 체간 대칭이 잘 유지되고 있습니다.
- **상체 부족**: 팔꿈치의 정렬이 부족하여 균형 유지에 어려움이 있을 수 있습니다.
- **하체 강점**: 엉덩이 관절의 정렬이 매우 잘 되어 있어 하체의 안정성을 나타냅니다.
- **하체 부족**: 왼쪽 무릎과 발목의 정렬이 부족하여 전체적인 자세에 악영향을 미치고 있습니다.

### 5. 개선할 수 있는 구체적인 조언
1. **무릎 정렬 연습**: 거울을 보면서 런지 동작을 실행하여 무릎이 두 번째 발가락 방향과 일직선을 유지하는지 확인하세요. 내반/외반이 발생하지 않도록 의식적으로 무릎 위치를 조절해보세요.
2. **발목 강도 향상**: 발목 근력을 강화하는 운동을 추가하여 안정성을 높이세요. 예를 들어, 발목 회전 운동이나 밸런스 훈련을 추천합니다.
3. **체간 안정성 훈련**: 코어 근육을 강화하여 체간의 안정성을 늘릴 수 있는 운동(예: 플랭크, 브릿지 등)을 포함시켜 보세요.
4. **천천히 동작하기**: 동작 속도를 줄여서 자세를 보다 정확히 유지하는 연습을 해보세요. 느리게 하면서 각 관절의 정렬을 체크하는 것이 좋습니다.
5. **전문가와의 상담**: 개인 트레이너나 물리치료사와 함께 자세 교정을 받는 것도 큰 도움이 될 것입니다.

이 피드백을 바탕으로 런지 동작을 개선해보세요! 운동에 대한 의지가 돋보입니다. 화이팅입니다!

## 런지 측면 영상에 대한 프롬프트
"""

# 측면용 프롬프트
def lunge_side_prompt(summary_json, exercise="런지"):
    summary = summary_json["summary"]
    avg_scores = summary_json["average_joint_scores"]

    prompt = f"""
너는 운동 코치 AI야. 아래는 사용자의 런지 측면 동작 평가 결과야.
JSON 데이터를 보고, 사용자가 이해할 수 있게 피드백을 해줘.

** 런지에 대한 설명
  런지는 시상면에서의 고관절 힌지와 슬관절 굴곡/신전의 협응을 요구하며, 체간-경골 각도의 조화와
  전방 무릎 이동, 전발 뒤꿈치 접지 유지가 정렬 안정성의 핵심이다.

** 주요 관절에 대한 설명
\t• 11: 왼쪽 어깨
\t• 12: 오른쪽 어깨
\t• 13: 왼쪽 팔꿈치
\t• 14: 오른쪽 팔꿈치
\t• 15: 왼쪽 손목
\t• 16: 오른쪽 손목
\t• 23: 왼쪽 엉덩이
\t• 24: 오른쪽 엉덩이
\t• 25: 왼쪽 무릎
\t• 26: 오른쪽 무릎
\t• 27: 왼쪽 발목
\t• 28: 오른쪽 발목

** 측면에서 바라봤을 때 런지 자세에 대한 설명
  측면 기준의 올바른 런지 핵심은 다음과 같다:
  1) 경골 vs 체간 각도: 하강 구간에서 경골과 체간이 유사한 기울기를 유지해 중심 이동을 균형화한다(과도한 전경/후경 금지).
  2) 전방 무릎 이동: 전발 무릎(25 또는 26)은 발끝을 과도하게 초과하지 않도록 하되, 개인 가동성/목표에 따라 제한적 전방 이동은 허용한다.
  3) 뒤꿈치 접지: 전발 뒤꿈치(27 또는 28)는 하강·상승 전 과정에서 접지를 유지해 족관절 배측굴곡 범위를 확보한다.
  4) 하강 깊이: 전발 대퇴가 지면과 거의 평행에 도달하도록 하되 요추 과신전/둔근 이완 없이 고관절을 우선적으로 굴곡한다.
  5) 보폭: 과소 보폭은 무릎 전방 이동 과다와 균형 불안을, 과대 보폭은 하강 제한과 고관절 신전 과부하를 유발하므로 중간 보폭을 유지한다.


** 평가 기준 (엄격 모드):
- joint_score >= 0.999 : 매우 잘함
- 0.985 ~ 0.997 : 부족
- 0.975 ~ 0.985 : 매우부족
- < 0.975 : 잘못됨

# 결과 요약:
라벨 비율 = {summary}
평균 관절 점수 = {avg_scores}

# 출력 지침:
1. 런지의 핵심 동작 기준과 비교해서 설명한다.
2. 주요 관절의 결과들을 보고 정확하게 피드백을 해준다. 하지만 관절 점수는 출력할 필요가 없다. 설명만 반드시 출력한다.
3. 전체적인 동작 평가 (라벨 비율 기반).
4. 상체(어깨/팔), 하체(엉덩이/무릎/발목) 강점과 부족한 점.
5. 개선할 수 있는 구체적인 조언을 제시.
"""
    return prompt

#측면, 영상에 대한 피드백
prompt = lunge_side_prompt(summary_data, exercise="런지")

response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role":"user","content": prompt}],
    temperature=0.7
)

print("\n LLM 피드백 결과:\n")
print(response.choices[0].message.content)

"""# LLM 답변:

### 런지 동작 평가 피드백

1. **런지의 핵심 동작 기준 비교**:
   - **경골 vs 체간 각도**: 경골과 체간의 기울기가 비슷해야 하는데, 당신의 동작에서는 전반적으로 안정적이나 일부 구간에서 불균형이 나타나는 것 같습니다.
   - **전방 무릎 이동**: 무릎이 발끝을 초과하지 않도록 해야 하는데, 현재 무릎의 위치가 과도하게 전방으로 이동하는 경향이 보입니다. 개인의 가동성에 따라 일부 전방 이동이 허용될 수 있지만, 현재는 주의가 필요합니다.
   - **뒤꿈치 접지**: 전발 뒤꿈치의 접지가 유지되고 있으나, 하강 및 상승 과정에서 불안정한 모습이 관찰됩니다. 이 부분에서 개선이 필요합니다.
   - **하강 깊이**: 대퇴가 지면과 거의 평행에 도달하지 못하고 있으며, 요추의 과신전이 나타나는 것으로 보입니다. 고관절의 굴곡을 우선적으로 고려해야 합니다.
   - **보폭**: 보폭이 적절하지 않아 무릎 전방 이동이 과다하게 나타나고 있으며, 이로 인해 균형이 불안정해 보입니다. 중간 보폭을 유지하는 것이 중요합니다.

2. **주요 관절 결과**:
   - 상체(어깨/팔) 부분은 비교적 안정적이며, 왼쪽 팔꿈치와 손목에서 약간의 부족함이 발견되었습니다. 이 부분은 주의가 필요합니다.
   - 하체(엉덩이/무릎/발목) 부분에서는 특히 왼쪽 무릎과 발목에서 점수가 낮아, 이 두 관절의 움직임이 불안정한 것으로 보입니다. 엉덩이와 대퇴는 상대적으로 잘 유지되고 있습니다.

3. **전체적인 동작 평가**:
   - 현재 동작에서 'NG' 비율이 59.1%로 매우 높은 상태입니다. 이는 여러 요소에서 개선이 필요함을 나타내며, 정확한 자세를 유지하기 위한 추가적인 연습이 요구됩니다.

4. **상체와 하체 강점 및 부족한 점**:
   - **강점**: 상체에서 어깨와 팔의 움직임은 안정적입니다. 오른쪽 팔꿈치와 손목의 점수는 양호합니다.
   - **부족한 점**: 왼쪽 팔꿈치와 손목의 움직임이 다소 부족하며, 하체에서는 특히 왼쪽 무릎과 발목의 안정성이 부족합니다.

5. **개선할 수 있는 구체적인 조언**:
   - **무릎의 위치 조정**: 런지 동작 시 무릎이 발끝을 초과하지 않도록 의식적으로 유지하며, 무릎의 전방 이동을 줄이세요.
   - **하체 근력 강화**: 왼쪽 무릎과 발목의 안정성을 높이기 위해 하체 근력 운동(스쿼트, 레그프레스 등)을 추가로 포함시키는 것이 좋습니다.
   - **운동 범위 조절**: 하강 깊이를 조절하여 대퇴가 지면과 평행에 가까워지도록 하며, 요추의 과신전을 방지하기 위한 복부 근육의 긴장을 유지해야 합니다.
   - **보폭 조정**: 보폭을 적절하게 조정하여 무릎의 위치를 안정화시키고, 균형을 유지할 수 있는 중간 보폭을 연습하세요.

이러한 점들을 개선해 나가면 런지 동작의 안정성과 효율성을 크게 향상시킬 수 있을 것입니다. 꾸준한 연습과 피드백을 통해 목표를 달성하시길 바랍니다!

# 하이니즈 영상에 대한 프롬프트
"""

import os
os.environ["OPENAI_API_KEY"] = ""

from openai import OpenAI
import json

client = OpenAI()


def build_highknees_prompt(summary_json, exercise="하이니즈", orientation="front"):
    summary = summary_json["summary"]
    avg_scores = summary_json["average_joint_scores"]

    if orientation == "front":
        exercise_desc = """
** 하이니즈 (정면) 기준 설명 **
- 상체를 곧게 세우고 시선을 정면으로 유지
- 무릎을 가슴 높이까지 들어올림
- 좌우 무릎이 균형 있게 올라가야 함
- 상체가 좌우로 흔들리지 않아야 함
"""
    elif orientation == "side":
        exercise_desc = """
** 하이니즈 (측면) 기준 설명 **
- 허벅지가 지면과 평행할 정도로 무릎 들어올림
- 상체는 곧게, 과도하게 숙이지 않음
- 착지 시 발끝부터 닿으며 충격 흡수
- 무릎과 발목이 일직선을 유지
- 리듬과 템포를 일정하게 유지
"""

    # 절대 기준 컷라인 설명 포함
    prompt = f"""
너는 운동 코치 AI야. 아래는 사용자의 {exercise} 동작 평가 결과야.
JSON 데이터를 보고, 사용자가 이해할 수 있게 피드백을 해줘.

** 하이니즈에 대한 설명
하이니즈는 제자리에서 무릎을 높게 들어올리며 달리기 동작을 반복하는
유산소 운동으로, 심폐 지구력과 하체 근력을 동시에 강화하는 데 효과적입니다.
올바른 하이니즈 자세는 다음과 같습니다:
{exercise_desc}


** 주요 관절에 대한 설명
	•	11: 왼쪽 어깨
	•	12: 오른쪽 어깨
	•	13: 왼쪽 팔꿈치
	•	14: 오른쪽 팔꿈치
	•	15: 왼쪽 손목
	•	16: 오른쪽 손목
	•	23: 왼쪽 엉덩이
	•	24: 오른쪽 엉덩이
	•	25: 왼쪽 무릎
	•	26: 오른쪽 무릎
	•	27: 왼쪽 발목
	•	28: 오른쪽 발목

** 관절 점수 해석 규칙 **
- 23-25, 24-26: 무릎 높이를 반영. 점수가 낮을 경우(0.97 이하) 무릎이 충분히 들어올려지지 않은 상태로 해석.
  → 양쪽 모두 낮으면 "무릎 높이가 전반적으로 낮습니다."로 표현하고, 한쪽만 낮으면 "좌우 높이 차이"로 표현한다.
- 23-24: 좌우 중심 불균형
- 25-27, 26-28: 착지나 다리 라인 불안정
- 11-13, 12-14: 팔 스윙 리듬/범위 차이

** 평가 기준 (엄격 모드):
- joint_score >= 0.999 : 매우 잘함
- 0.985 ~ 0.997 : 부족
- 0.975 ~ 0.985 : 매우부족
- < 0.975 : 잘못됨

# 결과 요약:
라벨 비율 = {summary}
평균 관절 점수 = {avg_scores}

# 출력 지침:
- {orientation} 기준으로 하이니즈의 핵심 동작과 비교하여 피드백한다.
- 관절 점수 해석 규칙과 주요 관절 결과를 참고하되, 수치는 직접 언급하지 않는다.
- 피드백은 전문 트레이너가 직접 말하듯 자연스럽고 따뜻한 문체로 작성하며, 약 5~8문장 내외로 구성한다.
- 문장은 ‘요약 → 원인 분석 → 개선 제안 → 격려’의 흐름으로 자연스럽게 이어지도록 작성한다.
- 상체(어깨·팔)와 하체(엉덩이·무릎·발목)의 강점과 개선점을 서술형으로 자연스럽게 녹인다.
- 다음 세트에서 개선할 수 있는 구체적인 조언을 제시한다.

"""
    return prompt



# 5. LLM 호출
prompt = build_highknees_prompt(summary_data, exercise="하이니즈", orientation="front")

response = client.chat.completions.create(
    model="gpt-4o-mini",   # Colab에서는 작은 모델 추천, 필요하면 gpt-4o로 교체
    messages=[{"role":"user","content": prompt}],
    temperature=0.7
)

print("\n LLM 피드백 결과:\n")
print(response.choices[0].message.content)

"""# LLM 답변:

안녕하세요! 하이니즈 동작 평가 결과를 바탕으로 피드백 드릴게요. 전체적으로 심폐 지구력과 하체 근력을 잘 활용하고 있지만, 몇 가지 개선할 점이 보입니다. 특히 상체의 팔 스윙과 하체의 무릎 높이에서 다소 부족함이 느껴집니다.

상체에서는 어깨와 팔의 리듬이 조금 더 일관되게 움직일 필요가 있습니다. 팔의 스윙 범위를 넓혀 상체가 흔들리지 않도록 하는 것이 중요해요. 하체에서는 무릎을 가슴 높이까지 올리는 것이 관건인데, 현재 한쪽 무릎의 높이가 낮아 균형이 깨지는 경향이 있습니다.

다음 세트에서는 무릎을 의식적으로 가슴 높이까지 들어올리며, 팔을 더 활발하게 휘저어 보세요. 조금씩 개선해 나가면 분명 좋은 결과가 있을 거예요. 계속해서 힘내고, 당신의 노력을 응원합니다!
"""